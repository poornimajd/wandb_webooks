The device being used is: cuda

Training Started.....
The training images
The original masks
Predicted masks
Epoch 0 : Lr (0.005)
		 Training Loss: 0.2239,  Training IoU: 0.000,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.1956,  Training IoU: 0.000,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.1681,  Training IoU: 0.013,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.1406,  Training IoU: 0.062,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.1221,  Training IoU: 0.115,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.1074,  Training IoU: 0.169,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.0957,  Training IoU: 0.214,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.0868,  Training IoU: 0.258,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.0775,  Training IoU: 0.301,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.0694,  Training IoU: 0.341,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.0605,  Training IoU: 0.380,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.0553,  Training IoU: 0.408,
Epoch 0 : Lr (0.005)
		 Training Loss: 0.0300,  Training IoU: 0.422,
		 Validation Loss: 2.7153,  Validation IoU: 0.045
Validation loss decreased (inf --> 2.715342). Saving model ...

Epoch 1 : Lr (0.005)
		 Training Loss: 0.1460,  Training IoU: 0.238,
Epoch 1 : Lr (0.005)
		 Training Loss: 0.2046,  Training IoU: 0.231,
Epoch 1 : Lr (0.005)
		 Training Loss: 0.1482,  Training IoU: 0.154,
Epoch 1 : Lr (0.005)
		 Training Loss: 0.0852,  Training IoU: 0.169,
Epoch 1 : Lr (0.005)
		 Training Loss: 0.0608,  Training IoU: 0.253,
Epoch 1 : Lr (0.005)
		 Training Loss: 0.0558,  Training IoU: 0.308,
Epoch 1 : Lr (0.005)
		 Training Loss: 0.0494,  Training IoU: 0.359,
Epoch 1 : Lr (0.005)
		 Training Loss: 0.0440,  Training IoU: 0.398,
Epoch 1 : Lr (0.005)
		 Training Loss: 0.1594,  Training IoU: 0.382,
Epoch 1 : Lr (0.005)
		 Training Loss: 0.0881,  Training IoU: 0.376,
Epoch 1 : Lr (0.005)
		 Training Loss: 0.7057,  Training IoU: 0.342,
Epoch 1 : Lr (0.005)
		 Training Loss: 11.8912,  Training IoU: 0.316,
Epoch 1 : Lr (0.005)
		 Training Loss: 8011330770477.7412,  Training IoU: 0.304,
		 Validation Loss: nan,  Validation IoU: 0.000
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 2 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
		 Validation Loss: nan,  Validation IoU: 0.000
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 3 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
		 Validation Loss: nan,  Validation IoU: 0.000
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 4 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
		 Validation Loss: nan,  Validation IoU: 0.000
The training images
The original masks
Predicted masks
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 5 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
		 Validation Loss: nan,  Validation IoU: 0.000
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 6 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
		 Validation Loss: nan,  Validation IoU: 0.000
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 7 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
		 Validation Loss: nan,  Validation IoU: 0.000
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 8 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
		 Validation Loss: nan,  Validation IoU: 0.000
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 9 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
		 Validation Loss: nan,  Validation IoU: 0.000
The training images
The original masks
Predicted masks
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 10 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
		 Validation Loss: nan,  Validation IoU: 0.000
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
Epoch 11 : Lr (0.005)
		 Training Loss: nan,  Training IoU: 0.000,
		 Validation Loss: nan,  Validation IoU: 0.000
Finished Training
